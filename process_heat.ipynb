{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699727f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import datetime as dt\n",
    "import sys\n",
    "import gsw as sw\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import cftime\n",
    "import coast\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57df360",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "var = 'thetao' # thetao, so, uo, vo, siconc, siage, sivol, sithick, siu, siv, \n",
    "i_o = 'O' # SI or O for sea ice or ocean\n",
    "freq = 'mon' # mon or day\n",
    "time_s = 'highres-future' # 'highres-future' or 'hist-1950'\n",
    "\n",
    "def make_path(var, i_o, freq, time_s):\n",
    "    if 'future' in time_s:\n",
    "        ddir = 'MOHC'\n",
    "    else:\n",
    "        ddir = 'NERC'\n",
    "    root = '/badc/cmip6/data/CMIP6/HighResMIP/' + ddir + '/HadGEM3-GC31-HH/' + time_s + '/r1i1p1f1/'\n",
    "    return root + i_o + freq + '/' + var + '/gn/latest/' + var + '_' + i_o + freq + '_HadGEM3-GC31-HH_' + time_s + '_r1i1p1f1_gn_*.nc'\n",
    "\n",
    "fn_nemo_dat_t1 = make_path('thetao', i_o, freq, 'hist-1950')\n",
    "fn_nemo_dat_s1 = make_path('so', i_o, freq, 'hist-1950')\n",
    "fn_nemo_dat_t2 = make_path('thetao', i_o, freq, time_s)\n",
    "fn_nemo_dat_s2 = make_path('so', i_o, freq, time_s)\n",
    "\n",
    "\n",
    "domain_root = '/gws/nopw/j04/nemo_vol5/acc/eORCA12-N512/domain/'\n",
    "fn_nemo_dom1 = domain_root + 'eORCA12_coordinates.nc'\n",
    "fn_nemo_dom = domain_root + 'mesh_mask_eORCA12_v2.4.nc'\n",
    "fn_nemo_bathy = domain_root + 'eORCA12_bathymetry_v2.4.nc'\n",
    "fn_config_t_grid = './config/gc31_nemo_grid_t.json'\n",
    "\n",
    "out_file = './Processed_test/' # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_coast = True # change\n",
    "use_xarray = 0#True\n",
    "use_dask = 0#True\n",
    "# change this to decrease resolution but decrease run time\n",
    "sub = 1\n",
    "\n",
    "now = dt.datetime.now()\n",
    "\n",
    "flist_t = sorted(glob.glob(fn_nemo_dat_t1))\n",
    "flist_s = sorted(glob.glob(fn_nemo_dat_s1))\n",
    "\n",
    "flist_t.extend(sorted(glob.glob(fn_nemo_dat_t2)))\n",
    "flist_t = flist_t[:12] # change\n",
    "flist_s.extend(sorted(glob.glob(fn_nemo_dat_s2)))\n",
    "flist_s = flist_s[:12]\n",
    "\n",
    "v_map = {}\n",
    "v_map['e1t'] = 'e1t'\n",
    "v_map['e2t'] = 'e2t'\n",
    "v_map['e3t_0'] = 'e3t_0'\n",
    "v_map['tmask'] = 'tmask'\n",
    "v_map['lat'] = 'latitude'\n",
    "v_map['lon'] = 'longitude'\n",
    "v_map['depth'] = 'lev'\n",
    "v_map['time'] = 'time'\n",
    "v_map['temp'] = 'thetao'\n",
    "v_map['sal'] = 'so' \n",
    "    \n",
    "if use_coast:\n",
    "    nemo_t = coast.Gridded(fn_data = flist_t[:12], fn_domain = fn_nemo_dom, config=fn_config_t_grid, multiple=True)\n",
    "    nemo_s = coast.Gridded(fn_data = flist_s[:12], fn_domain = fn_nemo_dom, config=fn_config_t_grid, multiple=True)\n",
    "    nemo_t.dataset['salinity'] = nemo_s.dataset.salinity\n",
    "\n",
    "    print(nemo_t.dataset.longitude.shape)\n",
    "    \n",
    "elif use_xarray:\n",
    "    with nc.Dataset(flist_t[0], 'r') as nc_fid:\n",
    "        lat = nc_fid.variables['latitude'][:]\n",
    "        lon = nc_fid.variables['longitude'][:]\n",
    "    \n",
    "    def _preprocess(ds, lon_bnds, lat_bnds):\n",
    "        return ds.isel(i=lon_bnds, j=lat_bnds)\n",
    "    \n",
    "    lon_bnds, lat_bnds = (-180, 180), (60, 90)\n",
    "    #lon_bnds, lat_bnds = (0, 180), (60, 90)\n",
    "    lat_sel = np.arange(np.min(np.nonzero((lat >= lat_bnds[0]))[0]), np.max(np.nonzero((lat <= lat_bnds[1]))[0]), sub)\n",
    "    lon_sel = np.arange(np.min(np.nonzero((lon >= lon_bnds[0]))[0]), np.max(np.nonzero((lon <= lon_bnds[1]))[0]), sub)\n",
    "    partial_func = partial(_preprocess, lon_bnds=lon_sel, lat_bnds=lat_sel)\n",
    "\n",
    "    my_chunks = {'j':50, 'i':50, 'time':1}\n",
    "    ds = xr.open_mfdataset(flist_t[:12], chunks=my_chunks, combine='nested', concat_dim='time', preprocess=partial_func, parallel=True).rename({\"thetao\": \"temperature\", \"lev\": \"z_dim\", \"i\": \"x_dim\", \"j\": \"y_dim\"})\n",
    "    ds_t = xr.open_mfdataset(flist_s[:12], chunks=my_chunks, combine='nested', concat_dim='time', preprocess=partial_func, parallel=True).rename({\"so\": \"salinity\", \"lev\": \"z_dim\", \"i\": \"x_dim\", \"j\": \"y_dim\"})\n",
    "    ds = ds.assign(salinity=ds_t.salinity)\n",
    "    \n",
    "elif use_dask:\n",
    "    with nc.Dataset(fn_nemo_dom, 'r') as nc_fid:\n",
    "        e1t = nc_fid.variables[v_map['e1t']][0, ...] # t, y, x\n",
    "        e2t = nc_fid.variables[v_map['e2t']][0, ...]\n",
    "        e3t = nc_fid.variables[v_map['e3t_0']][0, ...] # t, z, y, x\n",
    "        tmask = nc_fid.variables[v_map['tmask']][:, :, 1:-1, 1:-1]\n",
    "        \n",
    "    with nc.Dataset(flist_t[0], 'r') as nc_fid:\n",
    "        lat = nc_fid.variables[v_map['lat']][:]\n",
    "        lon = nc_fid.variables[v_map['lon']][:]\n",
    "        depth = nc_fid.variables[v_map['depth']][:]\n",
    "        temp = nc_fid.variables[v_map['temp']][:] # t, z, y, x\n",
    "\n",
    "    #def _preprocess(ds, lon_bnds, lat_bnds):\n",
    "    #    return ds.vindex([[:, :, lat_bnds, lon_bnds]])\n",
    "\n",
    "    lon_bnds, lat_bnds = (-180, 180), (60, 90)\n",
    "    y1 = np.min(np.nonzero((lat >= lat_bnds[0]))[0])\n",
    "    y2 = np.max(np.nonzero((lat <= lat_bnds[1]))[0])\n",
    "    x1 = np.min(np.nonzero((lon >= lon_bnds[0]))[0])\n",
    "    x2 = np.max(np.nonzero((lon <= lon_bnds[1]))[0])\n",
    "\n",
    "    lat = lat[y1:y2:sub, x1:x2:sub]\n",
    "    lon = lon[y1:y2:sub, x1:x2:sub]\n",
    "    tmask = (temp[:, :, y1:y2:sub, x1:x2:sub] == 1e20) | (tmask[:, :, y1:y2:sub, x1:x2:sub] == 0)\n",
    "    e1t = e1t[y1:y2:sub, x1:x2:sub]\n",
    "    e2t = e2t[y1:y2:sub, x1:x2:sub]\n",
    "    e3t = e3t[:, y1:y2:sub, x1:x2:sub]\n",
    "\n",
    "    def dask_load_ts(fnt, fns, tmask, y1, y2, x1, x2, sub):\n",
    "        lazy_arrays = [dask.delayed(nc.Dataset)(fn, 'r') for fn in fnt]\n",
    "        lazy_arrays = [dask.array.from_delayed(\n",
    "                            x.variables[v_map['temp']][:, :, y1:y2:sub, x1:x2:sub], shape=temp[:, :, y1:y2:sub, x1:x2:sub].shape, dtype=np.float64) \n",
    "                            for x in lazy_arrays]\n",
    "        ds_t = dask.array.concatenate(lazy_arrays[:], axis=0)\n",
    "        ds_t = ds_t.rechunk(chunks={0:1, 1:-1, 2:100, 3:100})#, balance=True)\n",
    "        tmask = dask.array.from_array(tmask)\n",
    "        tmask = tmask.rechunk(chunks={0:1, 1:-1, 2:100, 3:100})#, balance=True)\n",
    "        tmask = tmask.repeat(ds_t.shape[0], axis=0)\n",
    "        ds_t = dask.array.ma.masked_array(ds_t, mask=tmask)\n",
    "        print(ds_t) # t, z, y, x\n",
    "    \n",
    "        lazy_arrays = [dask.delayed(nc.Dataset)(fn, 'r') for fn in fns]\n",
    "        lazy_arrays = [dask.array.from_delayed(\n",
    "                            x.variables[v_map['sal']][:, :, y1:y2:sub, x1:x2:sub], shape=temp[:, :, y1:y2:sub, x1:x2:sub].shape, dtype=np.float64) \n",
    "                            for x in lazy_arrays]\n",
    "        ds_s = dask.array.concatenate(lazy_arrays[:], axis=0)\n",
    "        ds_s = ds_s.rechunk(chunks={0:1, 1:-1, 2:100, 3:100})#, balance=True)\n",
    "        ds_s = dask.array.ma.masked_array(ds_s, mask=tmask)\n",
    "        return ds_t, ds_s\n",
    "\n",
    "else: \n",
    "    with nc.Dataset(fn_nemo_dom, 'r') as nc_fid:\n",
    "        e1t = nc_fid.variables[v_map['e1t']][0, ...] # t, y, x\n",
    "        e2t = nc_fid.variables[v_map['e2t']][0, ...]\n",
    "        e3t = nc_fid.variables[v_map['e3t_0']][0, ...] # t, z, y, x\n",
    "        tmask = nc_fid.variables[v_map['tmask']][0, :, 1:-1, 1:-1]\n",
    "        \n",
    "    with nc.Dataset(flist_t[0], 'r') as nc_fid:\n",
    "        lat = nc_fid.variables[v_map['lat']][:]\n",
    "        lon = nc_fid.variables[v_map['lon']][:]\n",
    "        depth = nc_fid.variables[v_map['depth']][:]\n",
    "        temp = nc_fid.variables[v_map['temp']][0, ...]\n",
    "\n",
    "\n",
    "    lon_bnds, lat_bnds = (-180, 180), (60, 90)\n",
    "    lat_sel = np.arange(np.min(np.nonzero((lat >= lat_bnds[0]))[0]), np.max(np.nonzero((lat <= lat_bnds[1]))[0]), sub)\n",
    "    lon_sel = np.arange(np.min(np.nonzero((lon >= lon_bnds[0]))[0]), np.max(np.nonzero((lon <= lon_bnds[1]))[0]), sub)\n",
    "    \n",
    "    yi1 = lat_sel[0]\n",
    "    \n",
    "    temp = np.ma.masked_where((temp==1e20) | (tmask==1), temp)\n",
    "    mask = temp.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf5187-857b-47bd-90c4-22c1d3cd7cf8",
   "metadata": {},
   "source": [
    "Subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dec2799",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#print(nemo_t.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c5164b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "if use_coast:\n",
    "    yi1 = 2800\n",
    "    yi2 = nemo_t.dataset.longitude.shape[0]\n",
    "    ind_y = np.arange(yi1, yi2).astype(int)\n",
    "    #print(yi2, ind_y)\n",
    "    nemo_t_subset = nemo_t.isel(y_dim=ind_y)\n",
    "    print(nemo_t_subset.dataset)\n",
    "elif use_xarray | use_dask:\n",
    "    pass\n",
    "else:\n",
    "    lat = lat[yi1:, :]\n",
    "    lon = lon[yi1:, :]\n",
    "    mask = mask[:, yi1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c543ee-0efc-48cc-86a5-7139ab51579c",
   "metadata": {},
   "source": [
    "Time slice. Notes dates are 360 day years so use cftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967cfd1-5c17-4c46-bb59-b187eb9ad5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work\n",
    "#st_date = cftime.datetime(2050, 12, 1)\n",
    "#en_date = cftime.datetime(2051, 1, 1) \n",
    "#nemo_t_subset = nemo_t_subset.time_slice(st_date, en_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b58fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nemo_t_subset.construct_density(eos='EOS10')#, pot_dens=True)\n",
    "\n",
    "def calc_rho(sp, tp, depth, lon, lat):\n",
    "    pres = sw.p_from_z(depth * -1, lat)\n",
    "    sa = sw.SA_from_SP(sp, pres, lon, lat)\n",
    "    ct = sw.CT_from_pt(sa, tp)\n",
    "    rho = sw.rho(sa, ct, pres)\n",
    "    return rho, ct\n",
    "\n",
    "def calc_heat(rho, ct=[]):\n",
    "    if len(ct) == 0:\n",
    "        rho, ct = rho\n",
    "    cap = 3991.86795711963 # 3985 # J kg-1 K-1\n",
    "    #cap = sw.cp0 # use with conservative temp\n",
    "    return ct * rho * cap\n",
    "\n",
    "\n",
    "if use_coast:\n",
    "    ds_dom = xr.open_dataset(fn_nemo_dom).squeeze().rename({\"z\": \"z_dim\", \"x\": \"x_dim\", \"y\": \"y_dim\"})\n",
    "    #e1t = ds_dom.e1t[yi1+1:-1:sub, 1:-1:sub] # y, x\n",
    "    #e2t = ds_dom.e2t[yi1+1:-1:sub, 1:-1:sub]\n",
    "    #e3t = ds_dom.e3t_0[:, yi1+1:-1:sub, 1:-1:sub] # z, y, x\n",
    "    ind_y = np.arange(yi1+1, yi2-1, sub).astype(int)\n",
    "    ind_x = np.arange(1, nemo_t_subset.dataset.longitude.shape[1]-1, sub).astype(int)\n",
    "    e1t = ds_dom.e1t.isel(y_dim=ind_y, x_dim=ind_x) # y, x\n",
    "    e2t = ds_dom.e2t.isel(y_dim=ind_y, x_dim=ind_x)\n",
    "    e3t = ds_dom.e3t_0.isel(y_dim=ind_y, x_dim=ind_x) # z, y, x   \n",
    "elif use_xarray:\n",
    "    def _preprocess(ds, lon_bnds, lat_bnds):\n",
    "        return ds.isel(x=lon_bnds, y=lat_bnds)\n",
    "    \n",
    "    partial_func = partial(_preprocess, lon_bnds=lon_sel+1, lat_bnds=lat_sel+1)\n",
    "    my_chunks = {'y': 100, 'x': 100}                           \n",
    "    ds_dom = xr.open_mfdataset(fn_nemo_dom, chunks=my_chunks, combine='nested', preprocess=partial_func, parallel=True).squeeze().rename({\"z\": \"z_dim\", \"x\": \"x_dim\", \"y\": \"y_dim\"})\n",
    "    e1t = ds_dom.e1t # y, x\n",
    "    e2t = ds_dom.e2t\n",
    "    e3t = ds_dom.e3t_0 # z, y, x\n",
    "elif use_dask:\n",
    "    pass\n",
    "else:\n",
    "    e1t = e1t[yi1+1:-1:sub, 1:-1:sub] # y, x\n",
    "    e2t = e2t[yi1+1:-1:sub, 1:-1:sub]\n",
    "    e3t = e3t[:, yi1+1:-1:sub, 1:-1:sub] # z, y, x\n",
    "    \n",
    "e1t = np.tile(e1t, (e3t.shape[0], 1, 1))\n",
    "e2t = np.tile(e2t, (e3t.shape[0], 1, 1))\n",
    "print(e3t.shape, e1t.shape)\n",
    "volume = e1t * e2t * e3t\n",
    "\n",
    "      \n",
    "if use_coast:\n",
    "    ind_y = np.arange(0, nemo_t_subset.dataset.longitude.shape[0], sub).astype(int)\n",
    "    ind_x = np.arange(0, nemo_t_subset.dataset.longitude.shape[1], sub).astype(int)\n",
    "    nemo_t_subset = nemo_t_subset.isel(y_dim=ind_y, x_dim=ind_x)\n",
    "    lat = nemo_t_subset.dataset.latitude.values\n",
    "    lon = nemo_t_subset.dataset.longitude.values\n",
    "    #lat = nemo_t_subset.dataset.latitude.values[::sub, ::sub]\n",
    "    #lon = nemo_t_subset.dataset.longitude.values[::sub, ::sub]\n",
    "    depth = nemo_t_subset.dataset.depth_0.values[:]\n",
    "elif use_xarray:\n",
    "    #ind_y = np.arange(0, ds.longitude.shape[0], sub).astype(int)\n",
    "    #ind_x = np.arange(0, ds.longitude.shape[1], sub).astype(int)\n",
    "    #nemo_t_subset = ds.isel(j=ind_y, i=ind_x)\n",
    "    lat = ds.latitude.values\n",
    "    lon = ds.longitude.values\n",
    "    depth = ds.z_dim.values\n",
    "elif use_dask:\n",
    "    pass\n",
    "else:\n",
    "    lat = lat[::sub, ::sub]\n",
    "    lon = lon[::sub, ::sub]\n",
    "    mask = mask[:, ::sub, ::sub]\n",
    "\n",
    "depth_g = np.tile(depth, (lon.shape[1], lon.shape[0], 1)).T\n",
    "mask_south = np.zeros((lat.shape[0], lat.shape[1], 3), dtype=bool)\n",
    "mask_south[:, :, 0] = lat < 70\n",
    "mask_south[:, :, 1] = lat < 75\n",
    "mask_south[:, :, 2] = lat < 80\n",
    "\n",
    "if use_coast:\n",
    "    heat_time = np.ma.zeros((nemo_t_subset.dataset.t_dim.shape[0]))\n",
    "    date = np.zeros((nemo_t_subset.dataset.t_dim.shape[0]), dtype=object)\n",
    "    for i in range(nemo_t_subset.dataset.t_dim.shape[0]):\n",
    "        temp = nemo_t_subset.dataset.temperature.isel(t_dim=i).to_masked_array() # time, lev, j, i\n",
    "        sal = nemo_t_subset.dataset.salinity.isel(t_dim=i).to_masked_array()\n",
    "        #temp = nemo_t_subset.dataset.temperature[i, :, ::sub, ::sub].to_masked_array() # time, lev, j, i\n",
    "        #sal = nemo_t_subset.dataset.salinity[i, :, ::sub, ::sub].to_masked_array()\n",
    "        rho, ct = calc_rho(sal, temp, depth_g, lon, lat)\n",
    "        print(rho.size, volume.shape)\n",
    "    \n",
    "        heat_cont = np.ma.sum(calc_heat(rho, ct) * volume, axis=0) # vertically integrated\n",
    "        heat_pole = np.ma.masked_where(mask_south[:, :, 0], heat_cont)\n",
    "        heat_time[i] = np.ma.sum(heat_pole)\n",
    "        date[i] = nemo_t_subset.dataset.time.isel(t_dim=i).values\n",
    "        print(date[i])\n",
    "        \n",
    "elif use_xarray:\n",
    "    def hc(heat, volume):\n",
    "        return heat * volume\n",
    "    \n",
    "    heat_time = dask.array.zeros((ds.time.shape[0], 3))\n",
    "    date = np.zeros((ds.time.shape[0]), dtype=object)\n",
    "\n",
    "    if 1:\n",
    "        depth_g = xr.DataArray(depth_g, dims=(\"z_dim\", \"y_dim\", \"x_dim\")).chunk({'x_dim': 100, 'y_dim': 100})\n",
    "        volume = xr.DataArray(volume, dims=(\"z_dim\", \"y_dim\", \"x_dim\")).chunk({'x_dim': 100, 'y_dim': 100})\n",
    "        mask_south = xr.DataArray(np.invert(mask_south), dims=(\"y_dim\", \"x_dim\", \"band\")).chunk({'x_dim': 100, 'y_dim': 100})\n",
    "        date = ds.time.values\n",
    "        heat_time = (\n",
    "            hc(calc_heat(calc_rho(\n",
    "            ds.salinity, ds.temperature, depth_g, \n",
    "            ds.longitude.values, ds.latitude.values)), \n",
    "            volume)\n",
    "            .sum(dim='z_dim')\n",
    "            .expand_dims(dim={\"band\": 3})\n",
    "            .where(mask_south)\n",
    "            .sum(dim=['x_dim', 'y_dim'])\n",
    "            )\n",
    "        print(heat_time.shape)\n",
    "    else:\n",
    "        for i in range(ds.time.shape[0]):\n",
    "            rho, ct = calc_rho(ds.salinity.isel(time=i), ds.temperature.isel(time=i), depth_g, ds.longitude.values, ds.latitude.values)\n",
    "            heat = calc_heat(rho, ct)\n",
    "            print(heat.shape, volume.shape)\n",
    "            heat_v = hc(heat, volume)\n",
    "            heat_cont = dask.array.sum(heat_v, axis=0) # vertically integrated\n",
    "            heat_pole = dask.array.ma.masked_where(mask_south[:, :, 0], heat_cont)\n",
    "            heat_time[i] = dask.array.sum(heat_pole)\n",
    "            date[i] = ds.time.isel(time=i).values\n",
    "            print(date[i]) \n",
    "\n",
    "elif use_dask:\n",
    "    def hc(heat, volume):\n",
    "        return heat * volume\n",
    "\n",
    "    ref = 'days since 1950-01-01'\n",
    "    date = np.zeros((len(flist_t)), dtype=object)\n",
    "    for i in range(len(flist_t)):\n",
    "        with nc.Dataset(flist_t[i], 'r') as nc_fid:\n",
    "            time = nc_fid.variables[v_map['time']][:]\n",
    "        date[i] = cftime.num2date(time, ref, calendar='360_day')[0]\n",
    "        \n",
    "    lat_g = dask.array.from_array(lat[np.newaxis, np.newaxis, :, :], chunks={0:1, 0:-1, 1:100, 2:100})\n",
    "    lon_g = dask.array.from_array(lon[np.newaxis, np.newaxis, :, :], chunks={0:1, 0:-1, 1:100, 2:100})\n",
    "    depth_g = dask.array.from_array(depth_g[np.newaxis, :, :, :], chunks={0:1, 0:-1, 1:100, 2:100})\n",
    "    volume = dask.array.from_array(volume[np.newaxis, :, :, :], chunks={0:1, 0:-1, 1:100, 2:100})\n",
    "    mask_south = dask.array.from_array(mask_south[np.newaxis, :, :, :], chunks={0:1, 0:100, 1:100, 2:-1})\n",
    "    lat_g = lat_g.repeat(depth_g.shape[1], axis=1).repeat(12, axis=0)\n",
    "    lon_g = lon_g.repeat(depth_g.shape[1], axis=1).repeat(12, axis=0)\n",
    "    depth_g = depth_g.repeat(12, axis=0)\n",
    "    volume = volume.repeat(12, axis=0)\n",
    "    mask_south = mask_south.repeat(12, axis=0)\n",
    "\n",
    "    heat_time = np.ma.zeros((len(flist_t), 3))\n",
    "    for i in range(len(flist_t) // 12):\n",
    "        i1 = int(i * 12)\n",
    "        i2 = int((i + 1) * 12)\n",
    "        \n",
    "        ds_t, ds_s = dask_load_ts(flist_t[i1:i2], flist_s[i1:i2], tmask, y1, y2, x1, x2, sub)\n",
    "        \n",
    "        heat_part = (\n",
    "            dask.array.ma.masked_where(mask_south, \n",
    "            hc(\n",
    "            calc_heat(\n",
    "            calc_rho(\n",
    "            ds_s, ds_t, depth_g, \n",
    "            lon_g, lat_g)), \n",
    "            volume)        # t, z, y, x\n",
    "            .sum(axis=1)   # t, y, x\n",
    "            [:, :, :, np.newaxis].repeat(3, axis=3)) # t, y, x, mask\n",
    "            .sum(axis=(1, 2)) # t, mask\n",
    "            )\n",
    "        print(date[i1])\n",
    "        print(heat_part)\n",
    "        heat_time[i1:i2, :] = heat_part.compute()\n",
    "    print(heat_time.shape)\n",
    "    \n",
    "else:\n",
    "    heat_time = np.ma.zeros((len(flist_t), 3))\n",
    "    ref = 'days since 1950-01-01'\n",
    "    date = np.zeros((len(flist_t)), dtype=object)\n",
    "    for i in range(12):#len(flist_t)):\n",
    "        with nc.Dataset(flist_t[i], 'r') as nc_fid:\n",
    "            temp = nc_fid.variables[v_map['temp']][0, :, yi1::sub, ::sub] # time, lev, j, i\n",
    "            time = nc_fid.variables[v_map['time']][:]\n",
    "        with nc.Dataset(flist_s[i], 'r') as nc_fid:\n",
    "            sal = nc_fid.variables[v_map['sal']][0, :, yi1::sub, ::sub]\n",
    "        \n",
    "        temp = np.ma.masked_where((temp==1e20), temp)\n",
    "        sal = np.ma.masked_where((sal==1e20), sal)       \n",
    "        rho, ct = calc_rho(sal, temp, depth_g, lon, lat)\n",
    "    \n",
    "        heat_cont = np.ma.sum(calc_heat(rho, ct) * volume, axis=0) # vertically integrated\n",
    "        for j in range(mask_south.shape[2]):\n",
    "            heat_pole = np.ma.masked_where(mask_south[:, :, j], heat_cont)\n",
    "            heat_time[i, j] = np.ma.sum(heat_pole) \n",
    "        date[i] = cftime.num2date(time, ref, calendar='360_day')[0]\n",
    "        print(date[i])\n",
    "\n",
    "                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee167fa5-d9b1-46e5-831a-418c4666e2b7",
   "metadata": {},
   "source": [
    "Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8a29af-8460-4317-ad53-5679a2433bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Runtime:', dt.datetime.now() - now)\n",
    "print(heat_time)\n",
    "if use_dask:\n",
    "    heat_time = heat_time.filled(-1e20)\n",
    "np.savez(out_file + 'heat_content.npz', heat_time=heat_time, date=date)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
